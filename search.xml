<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title></title>
      <link href="/2023/12/15/CUDA%E5%AD%A6%E4%B9%A0/"/>
      <url>/2023/12/15/CUDA%E5%AD%A6%E4%B9%A0/</url>
      
        <content type="html"><![CDATA[<p>CUDA并行包括：线程并行、线程块并行、流并行</p><ul><li>线程并行：GPU同时执行多个线程，每个线程执行不同的计算任务，对不同的数据元素执行相同的操作</li><li>线程块并行：多个线程块的并行执行，线程块可以被组织成二维或者三维网格（grid）的形式<br><img src="https://cunxiao2002.oss-cn-beijing.aliyuncs.com/img/image-20240119165344995.png" alt="image-20240119165344995"></li></ul><p><strong>核函数调用</strong></p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">kernel_name&lt;&lt;&lt;grid,block&gt;&gt;&gt;(argument <span class="built_in">list</span>);</span><br><span class="line"><span class="comment">//kernel_name&lt;&lt;&lt;num_blocks, num_threads&gt;&gt;&gt;(argument list);</span></span><br><span class="line"></span><br><span class="line"><span class="meta">#example</span></span><br><span class="line">kernel_name&lt;&lt;&lt;<span class="number">4</span>,<span class="number">8</span>&gt;&gt;&gt;(argument <span class="built_in">list</span>); <span class="comment">//4grid，每个grid中8个thread</span></span><br></pre></td></tr></table></figure><p><img src="https://cunxiao2002.oss-cn-beijing.aliyuncs.com/img/image-20240119172046183.png" alt="image-20240119172046183"></p><p><strong>异步机制</strong><br>所有的cuda代码都是异步执行，当host启动kernel后，就会返回到host，而不是host等待device完成kernel的执行<br>下面是一些同步指令</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 显式同步:主机等待设备端执行</span></span><br><span class="line">cudaError_t <span class="title function_">cudaDeviceSynchronize</span><span class="params">(<span class="type">void</span>)</span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">//隐式同步:设备端不执行完，主机没办法进行，比如内存拷贝函数</span></span><br><span class="line">cudaError_t <span class="title function_">cudaMempy</span><span class="params">(<span class="type">void</span>* dst, <span class="type">const</span> <span class="type">void</span> *src, <span class="type">size_t</span> count, cudaMemcpyKind kind)</span>;</span><br></pre></td></tr></table></figure><p><strong>组织并行线程</strong><br><img src="https://cunxiao2002.oss-cn-beijing.aliyuncs.com/img/image-20240120003140201.png" alt="image-20240120003140201"></p><p>threadIdx是thread索引<br>blockIdx是线程块索引<br>blockDim是线程块大小</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 设备内存或者主机内存都是线性存在的,因此寻址方式如下</span></span><br><span class="line"><span class="type">int</span> ix = threadIdx.x + blockIdx.x * blockDim.x;</span><br><span class="line"><span class="type">int</span> iy = threadIdx.y + blockIdx.y * blockDim.y;</span><br><span class="line"></span><br><span class="line"><span class="type">unsigned</span> <span class="type">int</span> idx = iy * nx + ix;</span><br></pre></td></tr></table></figure><p><strong>GPU结构概述</strong><br>SM（stream multiple processor）：流式多处理器<br>线程束：CUDA采用SIMT架构管理thread，线程束的大小均为32，即在某时刻，SM上只执行一个线程束，也就是32个threads同时同步执行，每个线程束的threads执行同一条指令。<br><strong>Fermi架构</strong><br><img src="https://cunxiao2002.oss-cn-beijing.aliyuncs.com/img/image-20240121200841313.png" alt="image-20240121200841313"></p><p>上图有：</p><ol><li>512个cuda核</li><li>每个CUDA核心都有一个全流水线的整数算术逻辑单元ALU，和一个浮点数运算单元FPU</li><li>CUDA被分配到16个SM上<br>SM包括：</li><li>CUDA核</li><li>调度线程束的调度器和调度单元</li><li>共享内存、寄存器文件和一级缓存</li></ol><p><strong>线程束</strong><br>warp是SM中基本执行单元，当一个grid被启动（grid启动相当于一个内核被启动），grid中包含thread block，block被分配到一个SM上后会被分为多个warp，1 warp &#x3D; 32 threads。<strong>在一个warp中，所有threads按照SIMT的方式执行，每一步执行相同的指令，处理私有的数据</strong><br>当使用三维编号时，x位于最内层，y位于中层，z位于最外层，对应到C语言的三维数组就是</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">t[z][y][x]</span><br></pre></td></tr></table></figure><p>计算出三维对应的线性地址</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tid = threadIdx.x + theadIdx.y * blockDim.x + threadIdx.z * blockDim.x * blockDim.y</span><br></pre></td></tr></table></figure><p>一个线程块包含warp的数量：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">WarpPerBlock = <span class="built_in">ceil</span>(ThreadPerBlock / warpSize)</span><br><span class="line"><span class="comment">// ceil是向正无穷取整函数</span></span><br></pre></td></tr></table></figure><p>线程束的分化：同一个warp的thread执行不同的指令（比如if…else…），一部分threads符合if条件就会执行if后的语句，但是另外一部分不符合if后条件的thread在此时会停止执行指令，并不会跳过if去执行else指令，等if后的指令执行完后，才会去执行else后面的语句。<br>要想解决上述问题，需要避免在同一个warp内出现分化，也就是人为来设定warp，让同一个warp中的threads都执行同一条ins。</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 效率较低的kernel分支</span></span><br><span class="line">__global__ <span class="type">void</span> <span class="title function_">mathKernel1</span><span class="params">(<span class="type">float</span> *c)</span>&#123;</span><br><span class="line"><span class="type">int</span> tid = threadIdx.x + blockDim.x * blockIdx.x;</span><br><span class="line"><span class="type">float</span> a = <span class="number">0.0</span>;</span><br><span class="line"><span class="type">float</span> b = <span class="number">0.0</span>;</span><br><span class="line"><span class="keyword">if</span>(tid % <span class="number">2</span> == <span class="number">0</span>)</span><br><span class="line">a = <span class="number">100.0f</span>;</span><br><span class="line"><span class="keyword">else</span></span><br><span class="line">b = <span class="number">200.0f</span>;</span><br><span class="line"></span><br><span class="line">c[tid] = a + b;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 效率较高的kernel分支</span></span><br><span class="line"><span class="comment">// 第一个线程束内的线程编号tid从0到31，tid/warpSize都等于0，那么就都执行if语句。</span></span><br><span class="line"><span class="comment">// 第二个线程束内的线程编号tid从32到63，tid/warpSize都等于1，执行else</span></span><br><span class="line"><span class="comment">// 线程束内没有分支，效率较高。</span></span><br><span class="line">__global__ <span class="type">void</span> <span class="title function_">mathKernel2</span><span class="params">(<span class="type">float</span> *c)</span>&#123;</span><br><span class="line"><span class="type">int</span> tid = threadIdx.x + blockDim.x * blockIdx.x;</span><br><span class="line"><span class="type">int</span> warpSize = <span class="number">32</span>;</span><br><span class="line"><span class="type">float</span> a = <span class="number">0.0</span>;</span><br><span class="line"><span class="type">float</span> b = <span class="number">0.0</span>;</span><br><span class="line"><span class="keyword">if</span>((tid / warpSize) % <span class="number">2</span> == <span class="number">0</span>)</span><br><span class="line">a = <span class="number">100.0f</span>;</span><br><span class="line"><span class="keyword">else</span> </span><br><span class="line">b = <span class="number">200.0f</span>;</span><br><span class="line"></span><br><span class="line">c[tid] = a + b;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><strong>资源分配</strong><br>一个SM上分配多少warp取决于SM中可用的registers和shared memory大小<br>对于registers，more threads with fewer registers pre thread<br><img src="https://cunxiao2002.oss-cn-beijing.aliyuncs.com/img/image-20240123003531327.png" alt="image-20240123003531327"><br>对于shared memory，more blocks with less shared memory per block<br><img src="https://cunxiao2002.oss-cn-beijing.aliyuncs.com/img/image-20240123003733065.png" alt="image-20240123003733065"></p><h2 id="延迟隐藏"><a href="#延迟隐藏" class="headerlink" title="延迟隐藏"></a>延迟隐藏</h2><p>延迟通常包括两种：计算延迟（10-20 cycles）和内存延迟（400-800 cycles）</p><h2 id="规约问题"><a href="#规约问题" class="headerlink" title="规约问题"></a>规约问题</h2><p>reduce，将多个数字变成一个数字的操作（例如加法、乘法）<br>包括以下步骤：</p><ol><li>将一个长的输入向量划分成更小的块中</li><li>用一个thread计算部分和</li><li>将每个部分和相加得到最终的结果<br>常见两种配对方法</li><li>相邻配对<img src="https://cunxiao2002.oss-cn-beijing.aliyuncs.com/img/image-20240123172721866.png" alt="image-20240123172721866" style="zoom: 67%;" /></li><li>交错配对<img src="https://cunxiao2002.oss-cn-beijing.aliyuncs.com/img/image-20240123172807000.png" alt="image-20240123172807000" style="zoom:67%;" /></li></ol><p><strong>循环展开</strong></p><h2 id="内存"><a href="#内存" class="headerlink" title="内存"></a>内存</h2><h3 id="内存模型"><a href="#内存模型" class="headerlink" title="内存模型"></a>内存模型</h3><p>GPU上的内存设备有：</p><ul><li>寄存器（register）：thread</li><li>共享内存（shared memory）：每个block拥有，对block内所有的threads可见</li><li>本地内存</li><li>常量内存：只读，所有thread可见</li><li>纹理内存：只读，所有thread可见</li><li>全局内存：</li></ul><h3 id="内存管理"><a href="#内存管理" class="headerlink" title="内存管理"></a>内存管理</h3><p>GPU的内存管理主要涉及两点</p><ul><li>分配、释放设备内存</li><li>host与device传输内存</li></ul><h2 id="共享内存"><a href="#共享内存" class="headerlink" title="共享内存"></a>共享内存</h2><p>共享内存是和所对应的block同时建立的，block内的thread执行完后就会被释放，所以block和shared memory拥有相同的生命周期<br>声明shared memory有两个方法：静态、动态</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 静态，size_x,size_y要是一个确切的数字，不能是变量</span></span><br><span class="line">__shared__ <span class="type">float</span> a[size_x][size_y];</span><br><span class="line"></span><br><span class="line"><span class="comment">//动态，需要另加一个关键字，而且执行核函数的时候需要另加一个参数；</span></span><br><span class="line"><span class="comment">//tips：动态声明只支持一维</span></span><br><span class="line"><span class="keyword">extern</span> __shared__ <span class="type">int</span> tile[];</span><br><span class="line">kernel&lt;&lt;&lt;grid, block, isize * <span class="title function_">isizeof</span><span class="params">(<span class="type">int</span>)</span>&gt;&gt;&gt;;</span><br></pre></td></tr></table></figure><h3 id="bank-confilct"><a href="#bank-confilct" class="headerlink" title="bank confilct"></a>bank confilct</h3><p>shared memory会分为32个同样大小的内存模型（bank），对应32个threads。<br>如果thread在访问shared memory时都访问不同的bank，即没有产生conflict，那么一个事务就能完成，否则就需要多个内存事务。<br>$存储体索引 &#x3D; \frac{字节地址 \div 8}{存储体数} % 存储体数$<br>bank的宽度为8时bank排列图，每个bank被化成了左右两个部分，如果一个thread访问左边，而另一个thread访问右边，则不会产生conflict；同一个线程束访问同一个地址不会发生冲突（通过广播的方式来避免冲突）<br><img src="https://cunxiao2002.oss-cn-beijing.aliyuncs.com/img/image-20240127160214949.png" alt="image-20240127160214949"></p><p><strong>无冲突访问：</strong><br><img src="https://cunxiao2002.oss-cn-beijing.aliyuncs.com/img/image-20240127160516028.png" alt="image-20240127160516028"></p><p><img src="https://cunxiao2002.oss-cn-beijing.aliyuncs.com/img/image-20240127160523759.png" alt="image-20240127160523759"></p><p><strong>有冲突：</strong><br>有两个thread同时访问了一个 bank<br><img src="https://cunxiao2002.oss-cn-beijing.aliyuncs.com/img/image-20240127160558279.png" alt="image-20240127160558279" style="zoom:67%;" /><br><img src="https://cunxiao2002.oss-cn-beijing.aliyuncs.com/img/image-20240127160641771.png" alt="image-20240127160641771" style="zoom:67%;" /></p><h3 id="内存填充"><a href="#内存填充" class="headerlink" title="内存填充"></a>内存填充</h3><p>遇到严重冲突的时候，使用padding的方法让数据错位<br>如果不看最后一列的padding，那么在声明shared memory的时候只需要声明一个<code>__shared__ a[5][5]</code><br>如果我声明了一个<code>__shared__ a[5][6]</code>就会像下图一样多出来一列的padding<br><img src="https://cunxiao2002.oss-cn-beijing.aliyuncs.com/img/image-20240127161134431.png" alt="image-20240127161134431" style="zoom:50%;" /></p><p>在编译时，编译器会将二维数组重新分配bank，因为一共有5个bank，但是每一行有6个元素，就会错开元素<br><img src="https://cunxiao2002.oss-cn-beijing.aliyuncs.com/img/image-20240127161444115.png" alt="image-20240127161444115" style="zoom:50%;" /></p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//进行padding的代码</span></span><br><span class="line">__shared__ <span class="type">int</span> tile[N][N + padding]</span><br><span class="line"></span><br><span class="line"><span class="comment">//行不变，列填充以后的索引</span></span><br><span class="line">row_idx = (blockDim.x + <span class="number">1</span>) * threadIdx.y + threadIdx.x;</span><br><span class="line">col_idx = (blockDim.y + <span class="number">1</span>) * threadIdx.x + threadIdx.y;</span><br></pre></td></tr></table></figure><p>索引示意图：<br><img src="https://cunxiao2002.oss-cn-beijing.aliyuncs.com/img/image-20240127174322339.png" alt="image-20240127174322339" style="zoom:67%;" /></p><h3 id="共享内存的布局"><a href="#共享内存的布局" class="headerlink" title="共享内存的布局"></a>共享内存的布局</h3><p>首先我们要明白在CUDA中连续变化的是threadIdx.x</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">define</span> N 32</span></span><br><span class="line">__shared__ <span class="type">int</span> x[N][N];</span><br><span class="line"><span class="comment">//在索引的时候经常会用到下面的方式</span></span><br><span class="line"><span class="type">int</span> a = x[threadIdx.y][threadIdx.x];</span><br></pre></td></tr></table></figure><p>在这里就会产生一个疑问，为什么索引的时候用到的不是<code>a = x[threadIdx.x][threadIdx.y]</code>的方式？<br>这是因为threadIdx.x是连续变化的，对应到shared memory中是遍历同一行的不同列<br><img src="https://cunxiao2002.oss-cn-beijing.aliyuncs.com/img/image-20240127171335798.png" alt="image-20240127171335798"></p><p>如果使用<code>A[threadIdx.x][threadIdx.y]</code>访问的是绿框的部分，是最慢的的方案，而<code>A[threadIdx.y][threadIdx.x]</code>访问的才是红框</p><h2 id="线程束洗牌"><a href="#线程束洗牌" class="headerlink" title="线程束洗牌"></a>线程束洗牌</h2><p>一个warp有32 threads，也就是说这32 threads的寄存器变量在hardware上是邻居，说明warp内的threads相互访问数据不用通过shared memory或者global memory<br>线程束洗牌命令传递数据，延迟极低，且不消耗内存，是warp内通讯的极佳方式<br>束内线程（lane）指的是warp内的索引，所以lane的的范围在[0, 31]，且唯一。（这个唯一指的是在同一个warp内是唯一）</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">unsigned</span> <span class="type">int</span> LandID = threadIdx.x % <span class="number">32</span>;</span><br><span class="line"><span class="type">unsigned</span> <span class="type">int</span> warpID = threadIdx.x / <span class="number">32</span>;</span><br></pre></td></tr></table></figure>]]></content>
      
      
      
    </entry>
    
    
  
  
</search>
