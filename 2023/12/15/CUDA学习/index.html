<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 7.1.1">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/all.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"example.com","root":"/","scheme":"Muse","version":"7.8.0","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":false,"show_result":false,"style":null},"back2top":{"enable":true,"sidebar":false,"scrollpercent":false},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":false,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},"path":"search.xml"};
  </script>

  <meta name="description" content="CUDA并行包括：线程并行、线程块并行、流并行  线程并行：GPU同时执行多个线程，每个线程执行不同的计算任务，对不同的数据元素执行相同的操作 线程块并行：多个线程块的并行执行，线程块可以被组织成二维或者三维网格（grid）的形式  核函数调用 12345kernel_name&lt;&lt;&lt;grid,block&gt;&gt;&gt;(argument list);&#x2F;&#x2F;kernel_na">
<meta property="og:type" content="article">
<meta property="og:title" content="Cunxiao&#39;s blog">
<meta property="og:url" content="http://example.com/2023/12/15/CUDA%E5%AD%A6%E4%B9%A0/index.html">
<meta property="og:site_name" content="Cunxiao&#39;s blog">
<meta property="og:description" content="CUDA并行包括：线程并行、线程块并行、流并行  线程并行：GPU同时执行多个线程，每个线程执行不同的计算任务，对不同的数据元素执行相同的操作 线程块并行：多个线程块的并行执行，线程块可以被组织成二维或者三维网格（grid）的形式  核函数调用 12345kernel_name&lt;&lt;&lt;grid,block&gt;&gt;&gt;(argument list);&#x2F;&#x2F;kernel_na">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="https://cunxiao2002.oss-cn-beijing.aliyuncs.com/img/image-20240119165344995.png">
<meta property="og:image" content="https://cunxiao2002.oss-cn-beijing.aliyuncs.com/img/image-20240119172046183.png">
<meta property="og:image" content="https://cunxiao2002.oss-cn-beijing.aliyuncs.com/img/image-20240120003140201.png">
<meta property="og:image" content="https://cunxiao2002.oss-cn-beijing.aliyuncs.com/img/image-20240121200841313.png">
<meta property="og:image" content="https://cunxiao2002.oss-cn-beijing.aliyuncs.com/img/image-20240123003531327.png">
<meta property="og:image" content="https://cunxiao2002.oss-cn-beijing.aliyuncs.com/img/image-20240123003733065.png">
<meta property="og:image" content="https://cunxiao2002.oss-cn-beijing.aliyuncs.com/img/image-20240123172721866.png">
<meta property="og:image" content="https://cunxiao2002.oss-cn-beijing.aliyuncs.com/img/image-20240123172807000.png">
<meta property="og:image" content="https://cunxiao2002.oss-cn-beijing.aliyuncs.com/img/image-20240127160214949.png">
<meta property="og:image" content="https://cunxiao2002.oss-cn-beijing.aliyuncs.com/img/image-20240127160516028.png">
<meta property="og:image" content="https://cunxiao2002.oss-cn-beijing.aliyuncs.com/img/image-20240127160523759.png">
<meta property="og:image" content="https://cunxiao2002.oss-cn-beijing.aliyuncs.com/img/image-20240127160558279.png">
<meta property="og:image" content="https://cunxiao2002.oss-cn-beijing.aliyuncs.com/img/image-20240127160641771.png">
<meta property="og:image" content="https://cunxiao2002.oss-cn-beijing.aliyuncs.com/img/image-20240127161134431.png">
<meta property="og:image" content="https://cunxiao2002.oss-cn-beijing.aliyuncs.com/img/image-20240127161444115.png">
<meta property="og:image" content="https://cunxiao2002.oss-cn-beijing.aliyuncs.com/img/image-20240127174322339.png">
<meta property="og:image" content="https://cunxiao2002.oss-cn-beijing.aliyuncs.com/img/image-20240127171335798.png">
<meta property="article:published_time" content="2023-12-15T03:52:41.263Z">
<meta property="article:modified_time" content="2024-03-01T06:49:08.688Z">
<meta property="article:author" content="John Doe">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://cunxiao2002.oss-cn-beijing.aliyuncs.com/img/image-20240119165344995.png">

<link rel="canonical" href="http://example.com/2023/12/15/CUDA%E5%AD%A6%E4%B9%A0/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : false,
    isPost : true,
    lang   : 'en'
  };
</script>

  <title> | Cunxiao's blog</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="Toggle navigation bar">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">Cunxiao's blog</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-home fa-fw"></i>Home</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>Archives</a>

  </li>
  </ul>
</nav>




</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content post posts-expand">
            

    
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="http://example.com/2023/12/15/CUDA%E5%AD%A6%E4%B9%A0/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="John Doe">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Cunxiao's blog">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2023-12-15 11:52:41" itemprop="dateCreated datePublished" datetime="2023-12-15T11:52:41+08:00">2023-12-15</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2024-03-01 14:49:08" itemprop="dateModified" datetime="2024-03-01T14:49:08+08:00">2024-03-01</time>
              </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
        <p>CUDA并行包括：线程并行、线程块并行、流并行</p>
<ul>
<li>线程并行：GPU同时执行多个线程，每个线程执行不同的计算任务，对不同的数据元素执行相同的操作</li>
<li>线程块并行：多个线程块的并行执行，线程块可以被组织成二维或者三维网格（grid）的形式<br><img src="https://cunxiao2002.oss-cn-beijing.aliyuncs.com/img/image-20240119165344995.png" alt="image-20240119165344995"></li>
</ul>
<p><strong>核函数调用</strong></p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">kernel_name&lt;&lt;&lt;grid,block&gt;&gt;&gt;(argument <span class="built_in">list</span>);</span><br><span class="line"><span class="comment">//kernel_name&lt;&lt;&lt;num_blocks, num_threads&gt;&gt;&gt;(argument list);</span></span><br><span class="line"></span><br><span class="line"><span class="meta">#example</span></span><br><span class="line">kernel_name&lt;&lt;&lt;<span class="number">4</span>,<span class="number">8</span>&gt;&gt;&gt;(argument <span class="built_in">list</span>); <span class="comment">//4grid，每个grid中8个thread</span></span><br></pre></td></tr></table></figure>

<p><img src="https://cunxiao2002.oss-cn-beijing.aliyuncs.com/img/image-20240119172046183.png" alt="image-20240119172046183"></p>
<p><strong>异步机制</strong><br>所有的cuda代码都是异步执行，当host启动kernel后，就会返回到host，而不是host等待device完成kernel的执行<br>下面是一些同步指令</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 显式同步:主机等待设备端执行</span></span><br><span class="line">cudaError_t <span class="title function_">cudaDeviceSynchronize</span><span class="params">(<span class="type">void</span>)</span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">//隐式同步:设备端不执行完，主机没办法进行，比如内存拷贝函数</span></span><br><span class="line">cudaError_t <span class="title function_">cudaMempy</span><span class="params">(<span class="type">void</span>* dst, <span class="type">const</span> <span class="type">void</span> *src, <span class="type">size_t</span> count, cudaMemcpyKind kind)</span>;</span><br></pre></td></tr></table></figure>

<p><strong>组织并行线程</strong><br><img src="https://cunxiao2002.oss-cn-beijing.aliyuncs.com/img/image-20240120003140201.png" alt="image-20240120003140201"></p>
<p>threadIdx是thread索引<br>blockIdx是线程块索引<br>blockDim是线程块大小</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 设备内存或者主机内存都是线性存在的,因此寻址方式如下</span></span><br><span class="line"><span class="type">int</span> ix = threadIdx.x + blockIdx.x * blockDim.x;</span><br><span class="line"><span class="type">int</span> iy = threadIdx.y + blockIdx.y * blockDim.y;</span><br><span class="line"></span><br><span class="line"><span class="type">unsigned</span> <span class="type">int</span> idx = iy * nx + ix;</span><br></pre></td></tr></table></figure>

<p><strong>GPU结构概述</strong><br>SM（stream multiple processor）：流式多处理器<br>线程束：CUDA采用SIMT架构管理thread，线程束的大小均为32，即在某时刻，SM上只执行一个线程束，也就是32个threads同时同步执行，每个线程束的threads执行同一条指令。<br><strong>Fermi架构</strong><br><img src="https://cunxiao2002.oss-cn-beijing.aliyuncs.com/img/image-20240121200841313.png" alt="image-20240121200841313"></p>
<p>上图有：</p>
<ol>
<li>512个cuda核</li>
<li>每个CUDA核心都有一个全流水线的整数算术逻辑单元ALU，和一个浮点数运算单元FPU</li>
<li>CUDA被分配到16个SM上<br>SM包括：</li>
<li>CUDA核</li>
<li>调度线程束的调度器和调度单元</li>
<li>共享内存、寄存器文件和一级缓存</li>
</ol>
<p><strong>线程束</strong><br>warp是SM中基本执行单元，当一个grid被启动（grid启动相当于一个内核被启动），grid中包含thread block，block被分配到一个SM上后会被分为多个warp，1 warp &#x3D; 32 threads。<strong>在一个warp中，所有threads按照SIMT的方式执行，每一步执行相同的指令，处理私有的数据</strong><br>当使用三维编号时，x位于最内层，y位于中层，z位于最外层，对应到C语言的三维数组就是</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">t[z][y][x]</span><br></pre></td></tr></table></figure>
<p>计算出三维对应的线性地址</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tid = threadIdx.x + theadIdx.y * blockDim.x + threadIdx.z * blockDim.x * blockDim.y</span><br></pre></td></tr></table></figure>
<p>一个线程块包含warp的数量：</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">WarpPerBlock = <span class="built_in">ceil</span>(ThreadPerBlock / warpSize)</span><br><span class="line"><span class="comment">// ceil是向正无穷取整函数</span></span><br></pre></td></tr></table></figure>
<p>线程束的分化：同一个warp的thread执行不同的指令（比如if…else…），一部分threads符合if条件就会执行if后的语句，但是另外一部分不符合if后条件的thread在此时会停止执行指令，并不会跳过if去执行else指令，等if后的指令执行完后，才会去执行else后面的语句。<br>要想解决上述问题，需要避免在同一个warp内出现分化，也就是人为来设定warp，让同一个warp中的threads都执行同一条ins。</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 效率较低的kernel分支</span></span><br><span class="line">__global__ <span class="type">void</span> <span class="title function_">mathKernel1</span><span class="params">(<span class="type">float</span> *c)</span>&#123;</span><br><span class="line">	<span class="type">int</span> tid = threadIdx.x + blockDim.x * blockIdx.x;</span><br><span class="line">	<span class="type">float</span> a = <span class="number">0.0</span>;</span><br><span class="line">	<span class="type">float</span> b = <span class="number">0.0</span>;</span><br><span class="line">	<span class="keyword">if</span>(tid % <span class="number">2</span> == <span class="number">0</span>)</span><br><span class="line">		a = <span class="number">100.0f</span>;</span><br><span class="line">	<span class="keyword">else</span></span><br><span class="line">		b = <span class="number">200.0f</span>;</span><br><span class="line">	</span><br><span class="line">	c[tid] = a + b;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 效率较高的kernel分支</span></span><br><span class="line"><span class="comment">// 第一个线程束内的线程编号tid从0到31，tid/warpSize都等于0，那么就都执行if语句。</span></span><br><span class="line"><span class="comment">// 第二个线程束内的线程编号tid从32到63，tid/warpSize都等于1，执行else</span></span><br><span class="line"><span class="comment">// 线程束内没有分支，效率较高。</span></span><br><span class="line">__global__ <span class="type">void</span> <span class="title function_">mathKernel2</span><span class="params">(<span class="type">float</span> *c)</span>&#123;</span><br><span class="line">	<span class="type">int</span> tid = threadIdx.x + blockDim.x * blockIdx.x;</span><br><span class="line">	<span class="type">int</span> warpSize = <span class="number">32</span>;</span><br><span class="line">	<span class="type">float</span> a = <span class="number">0.0</span>;</span><br><span class="line">	<span class="type">float</span> b = <span class="number">0.0</span>;</span><br><span class="line">	<span class="keyword">if</span>((tid / warpSize) % <span class="number">2</span> == <span class="number">0</span>)</span><br><span class="line">		a = <span class="number">100.0f</span>;</span><br><span class="line">	<span class="keyword">else</span> </span><br><span class="line">		b = <span class="number">200.0f</span>;</span><br><span class="line">	</span><br><span class="line">	c[tid] = a + b;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p><strong>资源分配</strong><br>一个SM上分配多少warp取决于SM中可用的registers和shared memory大小<br>对于registers，more threads with fewer registers pre thread<br><img src="https://cunxiao2002.oss-cn-beijing.aliyuncs.com/img/image-20240123003531327.png" alt="image-20240123003531327"><br>对于shared memory，more blocks with less shared memory per block<br><img src="https://cunxiao2002.oss-cn-beijing.aliyuncs.com/img/image-20240123003733065.png" alt="image-20240123003733065"></p>
<h2 id="延迟隐藏"><a href="#延迟隐藏" class="headerlink" title="延迟隐藏"></a>延迟隐藏</h2><p>延迟通常包括两种：计算延迟（10-20 cycles）和内存延迟（400-800 cycles）</p>
<h2 id="规约问题"><a href="#规约问题" class="headerlink" title="规约问题"></a>规约问题</h2><p>reduce，将多个数字变成一个数字的操作（例如加法、乘法）<br>包括以下步骤：</p>
<ol>
<li>将一个长的输入向量划分成更小的块中</li>
<li>用一个thread计算部分和</li>
<li>将每个部分和相加得到最终的结果<br>常见两种配对方法</li>
<li>相邻配对<img src="https://cunxiao2002.oss-cn-beijing.aliyuncs.com/img/image-20240123172721866.png" alt="image-20240123172721866" style="zoom: 67%;" /></li>
<li>交错配对<img src="https://cunxiao2002.oss-cn-beijing.aliyuncs.com/img/image-20240123172807000.png" alt="image-20240123172807000" style="zoom:67%;" /></li>
</ol>
<p><strong>循环展开</strong></p>
<h2 id="内存"><a href="#内存" class="headerlink" title="内存"></a>内存</h2><h3 id="内存模型"><a href="#内存模型" class="headerlink" title="内存模型"></a>内存模型</h3><p>GPU上的内存设备有：</p>
<ul>
<li>寄存器（register）：thread</li>
<li>共享内存（shared memory）：每个block拥有，对block内所有的threads可见</li>
<li>本地内存</li>
<li>常量内存：只读，所有thread可见</li>
<li>纹理内存：只读，所有thread可见</li>
<li>全局内存：</li>
</ul>
<h3 id="内存管理"><a href="#内存管理" class="headerlink" title="内存管理"></a>内存管理</h3><p>GPU的内存管理主要涉及两点</p>
<ul>
<li>分配、释放设备内存</li>
<li>host与device传输内存</li>
</ul>
<h2 id="共享内存"><a href="#共享内存" class="headerlink" title="共享内存"></a>共享内存</h2><p>共享内存是和所对应的block同时建立的，block内的thread执行完后就会被释放，所以block和shared memory拥有相同的生命周期<br>声明shared memory有两个方法：静态、动态</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 静态，size_x,size_y要是一个确切的数字，不能是变量</span></span><br><span class="line">__shared__ <span class="type">float</span> a[size_x][size_y];</span><br><span class="line"></span><br><span class="line"><span class="comment">//动态，需要另加一个关键字，而且执行核函数的时候需要另加一个参数；</span></span><br><span class="line"><span class="comment">//tips：动态声明只支持一维</span></span><br><span class="line"><span class="keyword">extern</span> __shared__ <span class="type">int</span> tile[];</span><br><span class="line">kernel&lt;&lt;&lt;grid, block, isize * <span class="title function_">isizeof</span><span class="params">(<span class="type">int</span>)</span>&gt;&gt;&gt;;</span><br></pre></td></tr></table></figure>

<h3 id="bank-confilct"><a href="#bank-confilct" class="headerlink" title="bank confilct"></a>bank confilct</h3><p>shared memory会分为32个同样大小的内存模型（bank），对应32个threads。<br>如果thread在访问shared memory时都访问不同的bank，即没有产生conflict，那么一个事务就能完成，否则就需要多个内存事务。<br>$存储体索引 &#x3D; \frac{字节地址 \div 8}{存储体数} % 存储体数$<br>bank的宽度为8时bank排列图，每个bank被化成了左右两个部分，如果一个thread访问左边，而另一个thread访问右边，则不会产生conflict；同一个线程束访问同一个地址不会发生冲突（通过广播的方式来避免冲突）<br><img src="https://cunxiao2002.oss-cn-beijing.aliyuncs.com/img/image-20240127160214949.png" alt="image-20240127160214949"></p>
<p><strong>无冲突访问：</strong><br><img src="https://cunxiao2002.oss-cn-beijing.aliyuncs.com/img/image-20240127160516028.png" alt="image-20240127160516028"></p>
<p><img src="https://cunxiao2002.oss-cn-beijing.aliyuncs.com/img/image-20240127160523759.png" alt="image-20240127160523759"></p>
<p><strong>有冲突：</strong><br>有两个thread同时访问了一个 bank<br><img src="https://cunxiao2002.oss-cn-beijing.aliyuncs.com/img/image-20240127160558279.png" alt="image-20240127160558279" style="zoom:67%;" /><br><img src="https://cunxiao2002.oss-cn-beijing.aliyuncs.com/img/image-20240127160641771.png" alt="image-20240127160641771" style="zoom:67%;" /></p>
<h3 id="内存填充"><a href="#内存填充" class="headerlink" title="内存填充"></a>内存填充</h3><p>遇到严重冲突的时候，使用padding的方法让数据错位<br>如果不看最后一列的padding，那么在声明shared memory的时候只需要声明一个<code>__shared__ a[5][5]</code><br>如果我声明了一个<code>__shared__ a[5][6]</code>就会像下图一样多出来一列的padding<br><img src="https://cunxiao2002.oss-cn-beijing.aliyuncs.com/img/image-20240127161134431.png" alt="image-20240127161134431" style="zoom:50%;" /></p>
<p>在编译时，编译器会将二维数组重新分配bank，因为一共有5个bank，但是每一行有6个元素，就会错开元素<br><img src="https://cunxiao2002.oss-cn-beijing.aliyuncs.com/img/image-20240127161444115.png" alt="image-20240127161444115" style="zoom:50%;" /></p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//进行padding的代码</span></span><br><span class="line">__shared__ <span class="type">int</span> tile[N][N + padding]</span><br><span class="line"></span><br><span class="line"><span class="comment">//行不变，列填充以后的索引</span></span><br><span class="line">row_idx = (blockDim.x + <span class="number">1</span>) * threadIdx.y + threadIdx.x;</span><br><span class="line">col_idx = (blockDim.y + <span class="number">1</span>) * threadIdx.x + threadIdx.y;</span><br></pre></td></tr></table></figure>

<p>索引示意图：<br><img src="https://cunxiao2002.oss-cn-beijing.aliyuncs.com/img/image-20240127174322339.png" alt="image-20240127174322339" style="zoom:67%;" /></p>
<h3 id="共享内存的布局"><a href="#共享内存的布局" class="headerlink" title="共享内存的布局"></a>共享内存的布局</h3><p>首先我们要明白在CUDA中连续变化的是threadIdx.x</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">define</span> N 32</span></span><br><span class="line">__shared__ <span class="type">int</span> x[N][N];</span><br><span class="line"><span class="comment">//在索引的时候经常会用到下面的方式</span></span><br><span class="line"><span class="type">int</span> a = x[threadIdx.y][threadIdx.x];</span><br></pre></td></tr></table></figure>
<p>在这里就会产生一个疑问，为什么索引的时候用到的不是<code>a = x[threadIdx.x][threadIdx.y]</code>的方式？<br>这是因为threadIdx.x是连续变化的，对应到shared memory中是遍历同一行的不同列<br><img src="https://cunxiao2002.oss-cn-beijing.aliyuncs.com/img/image-20240127171335798.png" alt="image-20240127171335798"></p>
<p>如果使用<code>A[threadIdx.x][threadIdx.y]</code>访问的是绿框的部分，是最慢的的方案，而<code>A[threadIdx.y][threadIdx.x]</code>访问的才是红框</p>
<h2 id="线程束洗牌"><a href="#线程束洗牌" class="headerlink" title="线程束洗牌"></a>线程束洗牌</h2><p>一个warp有32 threads，也就是说这32 threads的寄存器变量在hardware上是邻居，说明warp内的threads相互访问数据不用通过shared memory或者global memory<br>线程束洗牌命令传递数据，延迟极低，且不消耗内存，是warp内通讯的极佳方式<br>束内线程（lane）指的是warp内的索引，所以lane的的范围在[0, 31]，且唯一。（这个唯一指的是在同一个warp内是唯一）</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">unsigned</span> <span class="type">int</span> LandID = threadIdx.x % <span class="number">32</span>;</span><br><span class="line"><span class="type">unsigned</span> <span class="type">int</span> warpID = threadIdx.x / <span class="number">32</span>;</span><br></pre></td></tr></table></figure>


    </div>

    
    
    

      <footer class="post-footer">

        


        
    <div class="post-nav">
      <div class="post-nav-item"></div>
      <div class="post-nav-item">
    <a href="/2024/04/06/hello-world/" rel="next" title="Hello World">
      Hello World <i class="fa fa-chevron-right"></i>
    </a></div>
    </div>
      </footer>
    
  </article>
  
  
  



          </div>
          

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          Table of Contents
        </li>
        <li class="sidebar-nav-overview">
          Overview
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
          <div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%BB%B6%E8%BF%9F%E9%9A%90%E8%97%8F"><span class="nav-number">1.</span> <span class="nav-text">延迟隐藏</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E8%A7%84%E7%BA%A6%E9%97%AE%E9%A2%98"><span class="nav-number">2.</span> <span class="nav-text">规约问题</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%86%85%E5%AD%98"><span class="nav-number">3.</span> <span class="nav-text">内存</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%86%85%E5%AD%98%E6%A8%A1%E5%9E%8B"><span class="nav-number">3.1.</span> <span class="nav-text">内存模型</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86"><span class="nav-number">3.2.</span> <span class="nav-text">内存管理</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%85%B1%E4%BA%AB%E5%86%85%E5%AD%98"><span class="nav-number">4.</span> <span class="nav-text">共享内存</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#bank-confilct"><span class="nav-number">4.1.</span> <span class="nav-text">bank confilct</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%86%85%E5%AD%98%E5%A1%AB%E5%85%85"><span class="nav-number">4.2.</span> <span class="nav-text">内存填充</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%85%B1%E4%BA%AB%E5%86%85%E5%AD%98%E7%9A%84%E5%B8%83%E5%B1%80"><span class="nav-number">4.3.</span> <span class="nav-text">共享内存的布局</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E7%BA%BF%E7%A8%8B%E6%9D%9F%E6%B4%97%E7%89%8C"><span class="nav-number">5.</span> <span class="nav-text">线程束洗牌</span></a></li></ol></div>
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <p class="site-author-name" itemprop="name">John Doe</p>
  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">2</span>
          <span class="site-state-item-name">posts</span>
        </a>
      </div>
  </nav>
</div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2024</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">John Doe</span>
</div>
  <div class="powered-by">Powered by <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> & <a href="https://muse.theme-next.org/" class="theme-link" rel="noopener" target="_blank">NexT.Muse</a>
  </div>

        








      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/muse.js"></script>


<script src="/js/next-boot.js"></script>




  















  

  

</body>
</html>
